{
  "best_global_step": 9000,
  "best_metric": 2.9958105087280273,
  "best_model_checkpoint": "./gpt2-lora-wikipedia\\checkpoint-9000",
  "epoch": 2.908929292929293,
  "eval_steps": 500,
  "global_step": 9000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03232323232323232,
      "grad_norm": 0.20696356892585754,
      "learning_rate": 5.94e-05,
      "loss": 3.5248,
      "step": 100
    },
    {
      "epoch": 0.06464646464646465,
      "grad_norm": 0.1513129323720932,
      "learning_rate": 0.0001194,
      "loss": 3.3551,
      "step": 200
    },
    {
      "epoch": 0.09696969696969697,
      "grad_norm": 0.15579192340373993,
      "learning_rate": 0.00017939999999999997,
      "loss": 3.3,
      "step": 300
    },
    {
      "epoch": 0.1292929292929293,
      "grad_norm": 0.16222023963928223,
      "learning_rate": 0.0002394,
      "loss": 3.2638,
      "step": 400
    },
    {
      "epoch": 0.16161616161616163,
      "grad_norm": 0.1893739402294159,
      "learning_rate": 0.00029939999999999996,
      "loss": 3.2294,
      "step": 500
    },
    {
      "epoch": 0.16161616161616163,
      "eval_loss": 3.0819597244262695,
      "eval_runtime": 7.565,
      "eval_samples_per_second": 132.187,
      "eval_steps_per_second": 16.523,
      "step": 500
    },
    {
      "epoch": 0.19393939393939394,
      "grad_norm": 0.18928663432598114,
      "learning_rate": 0.0002966180824413573,
      "loss": 3.2068,
      "step": 600
    },
    {
      "epoch": 0.22626262626262628,
      "grad_norm": 0.2185530662536621,
      "learning_rate": 0.000293202004099294,
      "loss": 3.2055,
      "step": 700
    },
    {
      "epoch": 0.2585858585858586,
      "grad_norm": 0.19458582997322083,
      "learning_rate": 0.00028978592575723067,
      "loss": 3.2069,
      "step": 800
    },
    {
      "epoch": 0.2909090909090909,
      "grad_norm": 0.17464479804039001,
      "learning_rate": 0.00028636984741516736,
      "loss": 3.191,
      "step": 900
    },
    {
      "epoch": 0.32323232323232326,
      "grad_norm": 0.20523133873939514,
      "learning_rate": 0.00028295376907310404,
      "loss": 3.1883,
      "step": 1000
    },
    {
      "epoch": 0.32323232323232326,
      "eval_loss": 3.0483009815216064,
      "eval_runtime": 6.4636,
      "eval_samples_per_second": 154.712,
      "eval_steps_per_second": 19.339,
      "step": 1000
    },
    {
      "epoch": 0.35555555555555557,
      "grad_norm": 0.20437197387218475,
      "learning_rate": 0.00027953769073104073,
      "loss": 3.169,
      "step": 1100
    },
    {
      "epoch": 0.3878787878787879,
      "grad_norm": 0.2304481416940689,
      "learning_rate": 0.00027612161238897747,
      "loss": 3.1796,
      "step": 1200
    },
    {
      "epoch": 0.4202020202020202,
      "grad_norm": 0.20510385930538177,
      "learning_rate": 0.0002727055340469141,
      "loss": 3.157,
      "step": 1300
    },
    {
      "epoch": 0.45252525252525255,
      "grad_norm": 0.22408322989940643,
      "learning_rate": 0.0002692894557048508,
      "loss": 3.171,
      "step": 1400
    },
    {
      "epoch": 0.48484848484848486,
      "grad_norm": 0.20090337097644806,
      "learning_rate": 0.0002658733773627875,
      "loss": 3.1659,
      "step": 1500
    },
    {
      "epoch": 0.48484848484848486,
      "eval_loss": 3.034905195236206,
      "eval_runtime": 6.484,
      "eval_samples_per_second": 154.226,
      "eval_steps_per_second": 19.278,
      "step": 1500
    },
    {
      "epoch": 0.5171717171717172,
      "grad_norm": 0.21885402500629425,
      "learning_rate": 0.00026245729902072415,
      "loss": 3.1682,
      "step": 1600
    },
    {
      "epoch": 0.5494949494949495,
      "grad_norm": 0.18681348860263824,
      "learning_rate": 0.0002590412206786609,
      "loss": 3.1596,
      "step": 1700
    },
    {
      "epoch": 0.5818181818181818,
      "grad_norm": 0.20394374430179596,
      "learning_rate": 0.0002556251423365976,
      "loss": 3.1549,
      "step": 1800
    },
    {
      "epoch": 0.6141414141414141,
      "grad_norm": 0.19422060251235962,
      "learning_rate": 0.00025220906399453426,
      "loss": 3.17,
      "step": 1900
    },
    {
      "epoch": 0.6464646464646465,
      "grad_norm": 0.22516727447509766,
      "learning_rate": 0.00024879298565247095,
      "loss": 3.1542,
      "step": 2000
    },
    {
      "epoch": 0.6464646464646465,
      "eval_loss": 3.0272958278656006,
      "eval_runtime": 6.465,
      "eval_samples_per_second": 154.68,
      "eval_steps_per_second": 19.335,
      "step": 2000
    },
    {
      "epoch": 0.6787878787878788,
      "grad_norm": 0.212408646941185,
      "learning_rate": 0.00024537690731040764,
      "loss": 3.1579,
      "step": 2100
    },
    {
      "epoch": 0.7111111111111111,
      "grad_norm": 0.19150467216968536,
      "learning_rate": 0.00024196082896834432,
      "loss": 3.1584,
      "step": 2200
    },
    {
      "epoch": 0.7434343434343434,
      "grad_norm": 0.20529356598854065,
      "learning_rate": 0.000238544750626281,
      "loss": 3.1513,
      "step": 2300
    },
    {
      "epoch": 0.7757575757575758,
      "grad_norm": 0.19456873834133148,
      "learning_rate": 0.00023512867228421772,
      "loss": 3.156,
      "step": 2400
    },
    {
      "epoch": 0.8080808080808081,
      "grad_norm": 0.20212678611278534,
      "learning_rate": 0.00023171259394215438,
      "loss": 3.1452,
      "step": 2500
    },
    {
      "epoch": 0.8080808080808081,
      "eval_loss": 3.0204527378082275,
      "eval_runtime": 6.577,
      "eval_samples_per_second": 152.044,
      "eval_steps_per_second": 19.005,
      "step": 2500
    },
    {
      "epoch": 0.8404040404040404,
      "grad_norm": 0.20945540070533752,
      "learning_rate": 0.0002282965156000911,
      "loss": 3.1425,
      "step": 2600
    },
    {
      "epoch": 0.8727272727272727,
      "grad_norm": 0.20846278965473175,
      "learning_rate": 0.00022488043725802777,
      "loss": 3.1418,
      "step": 2700
    },
    {
      "epoch": 0.9050505050505051,
      "grad_norm": 0.20099247992038727,
      "learning_rate": 0.00022146435891596443,
      "loss": 3.1447,
      "step": 2800
    },
    {
      "epoch": 0.9373737373737374,
      "grad_norm": 0.210893914103508,
      "learning_rate": 0.00021804828057390115,
      "loss": 3.1424,
      "step": 2900
    },
    {
      "epoch": 0.9696969696969697,
      "grad_norm": 0.2048088014125824,
      "learning_rate": 0.00021463220223183786,
      "loss": 3.1369,
      "step": 3000
    },
    {
      "epoch": 0.9696969696969697,
      "eval_loss": 3.015932559967041,
      "eval_runtime": 7.6156,
      "eval_samples_per_second": 131.309,
      "eval_steps_per_second": 16.414,
      "step": 3000
    },
    {
      "epoch": 1.001939393939394,
      "grad_norm": 0.2113160490989685,
      "learning_rate": 0.00021121612388977452,
      "loss": 3.1423,
      "step": 3100
    },
    {
      "epoch": 1.0342626262626262,
      "grad_norm": 0.20216183364391327,
      "learning_rate": 0.0002078000455477112,
      "loss": 3.133,
      "step": 3200
    },
    {
      "epoch": 1.0665858585858585,
      "grad_norm": 0.18576490879058838,
      "learning_rate": 0.00020438396720564791,
      "loss": 3.1414,
      "step": 3300
    },
    {
      "epoch": 1.0989090909090908,
      "grad_norm": 0.21115702390670776,
      "learning_rate": 0.00020096788886358457,
      "loss": 3.1405,
      "step": 3400
    },
    {
      "epoch": 1.1312323232323231,
      "grad_norm": 0.2143326699733734,
      "learning_rate": 0.00019755181052152128,
      "loss": 3.1353,
      "step": 3500
    },
    {
      "epoch": 1.1312323232323231,
      "eval_loss": 3.0122902393341064,
      "eval_runtime": 6.452,
      "eval_samples_per_second": 154.99,
      "eval_steps_per_second": 19.374,
      "step": 3500
    },
    {
      "epoch": 1.1635555555555555,
      "grad_norm": 0.20186126232147217,
      "learning_rate": 0.00019413573217945797,
      "loss": 3.1343,
      "step": 3600
    },
    {
      "epoch": 1.195878787878788,
      "grad_norm": 0.21577733755111694,
      "learning_rate": 0.00019071965383739466,
      "loss": 3.1526,
      "step": 3700
    },
    {
      "epoch": 1.2282020202020203,
      "grad_norm": 0.2075994312763214,
      "learning_rate": 0.00018730357549533134,
      "loss": 3.1415,
      "step": 3800
    },
    {
      "epoch": 1.2605252525252526,
      "grad_norm": 0.21904020011425018,
      "learning_rate": 0.00018388749715326805,
      "loss": 3.1307,
      "step": 3900
    },
    {
      "epoch": 1.292848484848485,
      "grad_norm": 0.22179557383060455,
      "learning_rate": 0.0001804714188112047,
      "loss": 3.1249,
      "step": 4000
    },
    {
      "epoch": 1.292848484848485,
      "eval_loss": 3.008715867996216,
      "eval_runtime": 6.4472,
      "eval_samples_per_second": 155.105,
      "eval_steps_per_second": 19.388,
      "step": 4000
    },
    {
      "epoch": 1.3251717171717172,
      "grad_norm": 0.22747771441936493,
      "learning_rate": 0.00017705534046914142,
      "loss": 3.1205,
      "step": 4100
    },
    {
      "epoch": 1.3574949494949495,
      "grad_norm": 0.24374741315841675,
      "learning_rate": 0.00017363926212707808,
      "loss": 3.1281,
      "step": 4200
    },
    {
      "epoch": 1.3898181818181818,
      "grad_norm": 0.23882892727851868,
      "learning_rate": 0.0001702231837850148,
      "loss": 3.1319,
      "step": 4300
    },
    {
      "epoch": 1.4221414141414142,
      "grad_norm": 0.23276670277118683,
      "learning_rate": 0.00016680710544295148,
      "loss": 3.1354,
      "step": 4400
    },
    {
      "epoch": 1.4544646464646465,
      "grad_norm": 0.19595867395401,
      "learning_rate": 0.00016339102710088814,
      "loss": 3.1381,
      "step": 4500
    },
    {
      "epoch": 1.4544646464646465,
      "eval_loss": 3.0067310333251953,
      "eval_runtime": 6.49,
      "eval_samples_per_second": 154.084,
      "eval_steps_per_second": 19.26,
      "step": 4500
    },
    {
      "epoch": 1.4867878787878788,
      "grad_norm": 0.23434197902679443,
      "learning_rate": 0.00015997494875882485,
      "loss": 3.1267,
      "step": 4600
    },
    {
      "epoch": 1.519111111111111,
      "grad_norm": 0.2147935926914215,
      "learning_rate": 0.00015655887041676156,
      "loss": 3.1285,
      "step": 4700
    },
    {
      "epoch": 1.5514343434343434,
      "grad_norm": 0.21511204540729523,
      "learning_rate": 0.00015314279207469822,
      "loss": 3.1329,
      "step": 4800
    },
    {
      "epoch": 1.5837575757575757,
      "grad_norm": 0.22419419884681702,
      "learning_rate": 0.0001497267137326349,
      "loss": 3.1207,
      "step": 4900
    },
    {
      "epoch": 1.6160808080808082,
      "grad_norm": 0.21694447100162506,
      "learning_rate": 0.00014631063539057162,
      "loss": 3.1334,
      "step": 5000
    },
    {
      "epoch": 1.6160808080808082,
      "eval_loss": 3.0047895908355713,
      "eval_runtime": 6.4462,
      "eval_samples_per_second": 155.13,
      "eval_steps_per_second": 19.391,
      "step": 5000
    },
    {
      "epoch": 1.6484040404040403,
      "grad_norm": 0.2405630648136139,
      "learning_rate": 0.0001428945570485083,
      "loss": 3.1308,
      "step": 5100
    },
    {
      "epoch": 1.6807272727272728,
      "grad_norm": 0.23806171119213104,
      "learning_rate": 0.000139478478706445,
      "loss": 3.1361,
      "step": 5200
    },
    {
      "epoch": 1.713050505050505,
      "grad_norm": 0.19959434866905212,
      "learning_rate": 0.00013606240036438168,
      "loss": 3.1212,
      "step": 5300
    },
    {
      "epoch": 1.7453737373737375,
      "grad_norm": 0.20696094632148743,
      "learning_rate": 0.00013264632202231836,
      "loss": 3.1208,
      "step": 5400
    },
    {
      "epoch": 1.7776969696969696,
      "grad_norm": 0.2214626669883728,
      "learning_rate": 0.00012923024368025505,
      "loss": 3.1104,
      "step": 5500
    },
    {
      "epoch": 1.7776969696969696,
      "eval_loss": 3.0024867057800293,
      "eval_runtime": 6.453,
      "eval_samples_per_second": 154.967,
      "eval_steps_per_second": 19.371,
      "step": 5500
    },
    {
      "epoch": 1.810020202020202,
      "grad_norm": 0.22075840830802917,
      "learning_rate": 0.00012581416533819176,
      "loss": 3.1258,
      "step": 5600
    },
    {
      "epoch": 1.8423434343434344,
      "grad_norm": 0.2269582450389862,
      "learning_rate": 0.00012239808699612844,
      "loss": 3.1163,
      "step": 5700
    },
    {
      "epoch": 1.8746666666666667,
      "grad_norm": 0.2118869423866272,
      "learning_rate": 0.00011898200865406512,
      "loss": 3.1343,
      "step": 5800
    },
    {
      "epoch": 1.906989898989899,
      "grad_norm": 0.23041528463363647,
      "learning_rate": 0.00011556593031200181,
      "loss": 3.1134,
      "step": 5900
    },
    {
      "epoch": 1.9393131313131313,
      "grad_norm": 0.20664426684379578,
      "learning_rate": 0.0001121498519699385,
      "loss": 3.1294,
      "step": 6000
    },
    {
      "epoch": 1.9393131313131313,
      "eval_loss": 3.000980854034424,
      "eval_runtime": 6.4858,
      "eval_samples_per_second": 154.184,
      "eval_steps_per_second": 19.273,
      "step": 6000
    },
    {
      "epoch": 1.9716363636363636,
      "grad_norm": 0.22847776114940643,
      "learning_rate": 0.00010873377362787518,
      "loss": 3.129,
      "step": 6100
    },
    {
      "epoch": 2.003878787878788,
      "grad_norm": 0.20837517082691193,
      "learning_rate": 0.00010531769528581187,
      "loss": 3.1409,
      "step": 6200
    },
    {
      "epoch": 2.0362020202020203,
      "grad_norm": 0.2243155688047409,
      "learning_rate": 0.00010190161694374857,
      "loss": 3.1115,
      "step": 6300
    },
    {
      "epoch": 2.0685252525252524,
      "grad_norm": 0.20862674713134766,
      "learning_rate": 9.848553860168525e-05,
      "loss": 3.1132,
      "step": 6400
    },
    {
      "epoch": 2.100848484848485,
      "grad_norm": 0.21169230341911316,
      "learning_rate": 9.506946025962194e-05,
      "loss": 3.1144,
      "step": 6500
    },
    {
      "epoch": 2.100848484848485,
      "eval_loss": 2.999554395675659,
      "eval_runtime": 6.4546,
      "eval_samples_per_second": 154.927,
      "eval_steps_per_second": 19.366,
      "step": 6500
    },
    {
      "epoch": 2.133171717171717,
      "grad_norm": 0.2394871860742569,
      "learning_rate": 9.165338191755864e-05,
      "loss": 3.1111,
      "step": 6600
    },
    {
      "epoch": 2.1654949494949496,
      "grad_norm": 0.24027128517627716,
      "learning_rate": 8.823730357549532e-05,
      "loss": 3.1173,
      "step": 6700
    },
    {
      "epoch": 2.1978181818181817,
      "grad_norm": 0.24290907382965088,
      "learning_rate": 8.482122523343201e-05,
      "loss": 3.1228,
      "step": 6800
    },
    {
      "epoch": 2.230141414141414,
      "grad_norm": 0.24468418955802917,
      "learning_rate": 8.140514689136871e-05,
      "loss": 3.1295,
      "step": 6900
    },
    {
      "epoch": 2.2624646464646463,
      "grad_norm": 0.23031310737133026,
      "learning_rate": 7.79890685493054e-05,
      "loss": 3.1193,
      "step": 7000
    },
    {
      "epoch": 2.2624646464646463,
      "eval_loss": 2.99892520904541,
      "eval_runtime": 6.4546,
      "eval_samples_per_second": 154.928,
      "eval_steps_per_second": 19.366,
      "step": 7000
    },
    {
      "epoch": 2.294787878787879,
      "grad_norm": 0.216594398021698,
      "learning_rate": 7.457299020724208e-05,
      "loss": 3.1255,
      "step": 7100
    },
    {
      "epoch": 2.327111111111111,
      "grad_norm": 0.21970616281032562,
      "learning_rate": 7.115691186517876e-05,
      "loss": 3.1181,
      "step": 7200
    },
    {
      "epoch": 2.3594343434343434,
      "grad_norm": 0.2073274850845337,
      "learning_rate": 6.774083352311545e-05,
      "loss": 3.1145,
      "step": 7300
    },
    {
      "epoch": 2.391757575757576,
      "grad_norm": 0.21633699536323547,
      "learning_rate": 6.432475518105215e-05,
      "loss": 3.116,
      "step": 7400
    },
    {
      "epoch": 2.424080808080808,
      "grad_norm": 0.21923884749412537,
      "learning_rate": 6.0908676838988834e-05,
      "loss": 3.1316,
      "step": 7500
    },
    {
      "epoch": 2.424080808080808,
      "eval_loss": 2.997703790664673,
      "eval_runtime": 6.4791,
      "eval_samples_per_second": 154.343,
      "eval_steps_per_second": 19.293,
      "step": 7500
    },
    {
      "epoch": 2.4564040404040406,
      "grad_norm": 0.21184177696704865,
      "learning_rate": 5.7492598496925526e-05,
      "loss": 3.1123,
      "step": 7600
    },
    {
      "epoch": 2.4887272727272727,
      "grad_norm": 0.23399904370307922,
      "learning_rate": 5.407652015486222e-05,
      "loss": 3.1183,
      "step": 7700
    },
    {
      "epoch": 2.521050505050505,
      "grad_norm": 0.2339874655008316,
      "learning_rate": 5.06604418127989e-05,
      "loss": 3.1208,
      "step": 7800
    },
    {
      "epoch": 2.5533737373737373,
      "grad_norm": 0.2507466971874237,
      "learning_rate": 4.724436347073559e-05,
      "loss": 3.1252,
      "step": 7900
    },
    {
      "epoch": 2.58569696969697,
      "grad_norm": 0.24705398082733154,
      "learning_rate": 4.382828512867228e-05,
      "loss": 3.1319,
      "step": 8000
    },
    {
      "epoch": 2.58569696969697,
      "eval_loss": 2.997046709060669,
      "eval_runtime": 6.4751,
      "eval_samples_per_second": 154.437,
      "eval_steps_per_second": 19.305,
      "step": 8000
    },
    {
      "epoch": 2.618020202020202,
      "grad_norm": 0.21608634293079376,
      "learning_rate": 4.0412206786608966e-05,
      "loss": 3.1238,
      "step": 8100
    },
    {
      "epoch": 2.6503434343434344,
      "grad_norm": 0.2519351541996002,
      "learning_rate": 3.699612844454566e-05,
      "loss": 3.1126,
      "step": 8200
    },
    {
      "epoch": 2.6826666666666665,
      "grad_norm": 0.21009483933448792,
      "learning_rate": 3.3580050102482344e-05,
      "loss": 3.1143,
      "step": 8300
    },
    {
      "epoch": 2.714989898989899,
      "grad_norm": 0.23620334267616272,
      "learning_rate": 3.016397176041904e-05,
      "loss": 3.1186,
      "step": 8400
    },
    {
      "epoch": 2.747313131313131,
      "grad_norm": 0.2432287335395813,
      "learning_rate": 2.6747893418355725e-05,
      "loss": 3.1214,
      "step": 8500
    },
    {
      "epoch": 2.747313131313131,
      "eval_loss": 2.996562957763672,
      "eval_runtime": 6.482,
      "eval_samples_per_second": 154.273,
      "eval_steps_per_second": 19.284,
      "step": 8500
    },
    {
      "epoch": 2.7796363636363637,
      "grad_norm": 0.2379739135503769,
      "learning_rate": 2.3331815076292414e-05,
      "loss": 3.111,
      "step": 8600
    },
    {
      "epoch": 2.811959595959596,
      "grad_norm": 0.22503884136676788,
      "learning_rate": 1.9915736734229102e-05,
      "loss": 3.125,
      "step": 8700
    },
    {
      "epoch": 2.8442828282828283,
      "grad_norm": 0.22196471691131592,
      "learning_rate": 1.6499658392165794e-05,
      "loss": 3.1146,
      "step": 8800
    },
    {
      "epoch": 2.8766060606060604,
      "grad_norm": 0.234700009226799,
      "learning_rate": 1.3083580050102481e-05,
      "loss": 3.1099,
      "step": 8900
    },
    {
      "epoch": 2.908929292929293,
      "grad_norm": 0.2324593961238861,
      "learning_rate": 9.66750170803917e-06,
      "loss": 3.1239,
      "step": 9000
    },
    {
      "epoch": 2.908929292929293,
      "eval_loss": 2.9958105087280273,
      "eval_runtime": 6.4606,
      "eval_samples_per_second": 154.784,
      "eval_steps_per_second": 19.348,
      "step": 9000
    }
  ],
  "logging_steps": 100,
  "max_steps": 9282,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 7.575284198176358e+16,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
